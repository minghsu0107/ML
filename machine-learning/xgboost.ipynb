{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xgboost.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minghsu0107/ML/blob/master/machine-learning/xgboost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UpYPY6q_ccJ",
        "colab_type": "text"
      },
      "source": [
        "## Play with Iris Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j57fHMjvWfkg",
        "colab_type": "code",
        "outputId": "3e63c564-b690-4fb6-f8ee-0fd7d6741ce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "print(X.shape)\n",
        "print(iris.target_names)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 4)\n",
            "['setosa' 'versicolor' 'virginica']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB2IaXgb_ggX",
        "colab_type": "code",
        "outputId": "5b452a6e-3eb6-4b1a-939b-e2154b926157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train.shape, y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((120, 4), (120,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pD3P-AN-7AU",
        "colab_type": "code",
        "outputId": "8e998db9-7e98-446e-9ef5-9c105a49e053",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "dtrain.save_binary('dtrain.buffer')\n",
        "dtest.save_binary('dtest.buffer')\n",
        "\n",
        "dtrain = xgb.DMatrix('dtrain.buffer')\n",
        "dtest = xgb.DMatrix('dtest.buffer')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[03:11:20] 120x4 matrix with 480 entries loaded from dtrain.buffer\n",
            "[03:11:20] 30x4 matrix with 120 entries loaded from dtest.buffer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlIjD6ErBHtj",
        "colab_type": "text"
      },
      "source": [
        "If you want to use svmlight for less memory consumption, first dump the numpy array into svmlight format and then just pass the filename to DMatrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrSjUINbATwv",
        "colab_type": "code",
        "outputId": "f17a7597-d771-49cf-c507-75e71f875f7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.datasets import dump_svmlight_file\n",
        "\n",
        "dump_svmlight_file(X_train, y_train, 'dtrain.svm', zero_based=True)\n",
        "dump_svmlight_file(X_test, y_test, 'dtest.svm', zero_based=True)\n",
        "dtrain_svm = xgb.DMatrix('dtrain.svm')\n",
        "dtest_svm = xgb.DMatrix('dtest.svm')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[03:11:20] 120x4 matrix with 480 entries loaded from dtrain.svm\n",
            "[03:11:20] 30x4 matrix with 120 entries loaded from dtest.svm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zvOzymeCgX7",
        "colab_type": "text"
      },
      "source": [
        "Generally try with eta 0.1, 0.2, 0.3, max_depth in range of 2 to 10 and num_round around few hundred."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mUApdpOAeCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param = {\n",
        "    'booster': 'gbtree',\n",
        "    'max_depth': 3,  # the maximum depth of each tree\n",
        "    'eta': 0.3,  # the training step for each iteration\n",
        "    'silent': 1,  # logging mode - quiet\n",
        "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
        "    'num_class': 3}  # the number of classes that exist in this datset\n",
        "num_round = 20  # the number of training iterations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VpFZ3I_CVtr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bst = xgb.train(param, dtrain_svm, num_round)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nYhSRT3Cnie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bst.dump_model('dump.raw.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QYM5jRjCwPM",
        "colab_type": "code",
        "outputId": "1657b141-397f-47f6-e74c-c170d6b88c7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "preds = bst.predict(dtest)\n",
        "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "best_preds"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
              "       0, 2, 2, 2, 2, 2, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15pfJ9dRFCEV",
        "colab_type": "code",
        "outputId": "41791bbe-c4d0-48ff-c751-fcc03d255131",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "print(precision_score(y_test, best_preds, average='macro'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgJ933pd53Gm",
        "colab_type": "text"
      },
      "source": [
        "We  can save the model for further usage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQUjjVWnFsxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bst.save_model('iris_bst.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUtfr2kS3lHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clf = xgb.Booster()\n",
        "#clf.load_model('iris_bst.model')\n",
        "clf = xgb.Booster(model_file='iris_bst.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9gEgMux33Q5",
        "colab_type": "code",
        "outputId": "3b85a691-7236-4b4b-ad66-388dc643b9d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "clf.predict(dtest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00563804, 0.97755206, 0.01680986],\n",
              "       [0.98254657, 0.01395846, 0.00349498],\n",
              "       [0.0036375 , 0.00615226, 0.9902103 ],\n",
              "       [0.00564738, 0.97917044, 0.0151822 ],\n",
              "       [0.00540075, 0.93640935, 0.0581899 ],\n",
              "       [0.98607963, 0.0104128 , 0.00350755],\n",
              "       [0.00438964, 0.99041265, 0.0051977 ],\n",
              "       [0.0156953 , 0.06653062, 0.91777414],\n",
              "       [0.0063378 , 0.94877166, 0.04489056],\n",
              "       [0.00438964, 0.99041265, 0.0051977 ],\n",
              "       [0.01785045, 0.07566603, 0.9064836 ],\n",
              "       [0.99054164, 0.00561866, 0.00383973],\n",
              "       [0.98254657, 0.01395846, 0.00349498],\n",
              "       [0.990855  , 0.00562044, 0.00352453],\n",
              "       [0.990855  , 0.00562044, 0.00352453],\n",
              "       [0.00435676, 0.9863815 , 0.00926175],\n",
              "       [0.0028351 , 0.00545694, 0.991708  ],\n",
              "       [0.00506935, 0.98753244, 0.00739827],\n",
              "       [0.00435527, 0.98265946, 0.01298527],\n",
              "       [0.00283684, 0.00484793, 0.9923152 ],\n",
              "       [0.990855  , 0.00562044, 0.00352453],\n",
              "       [0.01177546, 0.08546326, 0.90276134],\n",
              "       [0.990855  , 0.00562044, 0.00352453],\n",
              "       [0.00283684, 0.00484793, 0.9923152 ],\n",
              "       [0.00561747, 0.01081239, 0.98357016],\n",
              "       [0.00363441, 0.00699543, 0.9893701 ],\n",
              "       [0.0036375 , 0.00615226, 0.9902103 ],\n",
              "       [0.00561747, 0.01081239, 0.98357016],\n",
              "       [0.99054164, 0.00561866, 0.00383973],\n",
              "       [0.990855  , 0.00562044, 0.00352453]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF_pDmNY4Bqd",
        "colab_type": "code",
        "outputId": "bd523090-4645-45ac-f97b-47b765a8953d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "from xgboost import plot_importance\n",
        "print(clf.get_fscore())\n",
        "plot_importance(clf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'f2': 91, 'f3': 44, 'f0': 19, 'f1': 18}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6100175278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNdN7goXMzt5",
        "colab_type": "code",
        "outputId": "d96f58df-bc70-4575-8949-06ec49a967e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "dir(clf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__copy__',\n",
              " '__deepcopy__',\n",
              " '__del__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_validate_features',\n",
              " 'attr',\n",
              " 'attributes',\n",
              " 'boost',\n",
              " 'booster',\n",
              " 'copy',\n",
              " 'dump_model',\n",
              " 'eval',\n",
              " 'eval_set',\n",
              " 'feature_names',\n",
              " 'feature_types',\n",
              " 'get_dump',\n",
              " 'get_fscore',\n",
              " 'get_score',\n",
              " 'get_split_value_histogram',\n",
              " 'handle',\n",
              " 'load_model',\n",
              " 'load_rabit_checkpoint',\n",
              " 'predict',\n",
              " 'save_model',\n",
              " 'save_rabit_checkpoint',\n",
              " 'save_raw',\n",
              " 'set_attr',\n",
              " 'set_param',\n",
              " 'trees_to_dataframe',\n",
              " 'update']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3eZgmVX6jvd",
        "colab_type": "text"
      },
      "source": [
        "We can also continue training on the existed model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VFdgi8k5DbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bst = xgb.train(param, dtest, num_round, xgb_model='iris_bst.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw5b4hda66Ox",
        "colab_type": "code",
        "outputId": "b327a7c4-19c1-48c5-c26f-3198e42c50a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "bst.predict(dtest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00626042, 0.97150415, 0.02223538],\n",
              "       [0.9833303 , 0.01250299, 0.00416675],\n",
              "       [0.00305996, 0.00463209, 0.9923079 ],\n",
              "       [0.00627413, 0.9736327 , 0.02009312],\n",
              "       [0.00591656, 0.9181438 , 0.07593963],\n",
              "       [0.98649627, 0.00932354, 0.00418016],\n",
              "       [0.0048936 , 0.98820364, 0.00690268],\n",
              "       [0.01343146, 0.05095716, 0.93561137],\n",
              "       [0.00697244, 0.93419635, 0.05883117],\n",
              "       [0.0048936 , 0.98820364, 0.00690268],\n",
              "       [0.01531663, 0.05810924, 0.9265741 ],\n",
              "       [0.9903985 , 0.00502806, 0.00457345],\n",
              "       [0.9833303 , 0.01250299, 0.00416675],\n",
              "       [0.9907718 , 0.00502995, 0.00419828],\n",
              "       [0.9907718 , 0.00502995, 0.00419828],\n",
              "       [0.00485046, 0.9828661 , 0.01228339],\n",
              "       [0.00238424, 0.00410734, 0.99350846],\n",
              "       [0.0056468 , 0.984536  , 0.00981717],\n",
              "       [0.00484286, 0.97795653, 0.01720059],\n",
              "       [0.00238534, 0.0036484 , 0.9939663 ],\n",
              "       [0.9907718 , 0.00502995, 0.00419828],\n",
              "       [0.01011908, 0.06573138, 0.9241496 ],\n",
              "       [0.9907718 , 0.00502995, 0.00419828],\n",
              "       [0.00238534, 0.0036484 , 0.9939663 ],\n",
              "       [0.00473257, 0.00815282, 0.98711467],\n",
              "       [0.003058  , 0.00526804, 0.991674  ],\n",
              "       [0.00305996, 0.00463209, 0.9923079 ],\n",
              "       [0.00473257, 0.00815282, 0.98711467],\n",
              "       [0.9903985 , 0.00502806, 0.00457345],\n",
              "       [0.9907718 , 0.00502995, 0.00419828]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMKSl_al-L05",
        "colab_type": "text"
      },
      "source": [
        "## Incremental Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYgJAolF-R04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.metrics import mean_absolute_error as mae"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg36NSCwAMP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "boston = load_boston()\n",
        "features = boston.feature_names\n",
        "X = boston.data\n",
        "y = boston.target\n",
        "\n",
        "X=pd.DataFrame(X,columns=features)\n",
        "y = pd.Series(y, index=X.index)\n",
        "\n",
        "# split data into training and testing sets\n",
        "# n_splits = 1: split for one time\n",
        "rs = ShuffleSplit(test_size=0.3, n_splits=1, random_state=10)\n",
        "for train_idx, test_idx in rs.split(X):  # this looks silly\n",
        "    pass\n",
        "\n",
        "train_split = round(len(train_idx) / 2)\n",
        "train1_idx = train_idx[:train_split]\n",
        "train2_idx = train_idx[train_split:]\n",
        "\n",
        "X_train = X.loc[train_idx]\n",
        "X_train_1 = X.loc[train1_idx]\n",
        "X_train_2 = X.loc[train2_idx]\n",
        "X_test = X.loc[test_idx]\n",
        "\n",
        "y_train = y.loc[train_idx]\n",
        "y_train_1 = y.loc[train1_idx]\n",
        "y_train_2 = y.loc[train2_idx]\n",
        "y_test = y.loc[test_idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r5xId8uAfbe",
        "colab_type": "code",
        "outputId": "c0f0b0ea-648c-4969-a8d6-5cc10de198d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "xg_train_0 = xgb.DMatrix(X_train, label=y_train)\n",
        "xg_train_1 = xgb.DMatrix(X_train_1, label=y_train_1)\n",
        "xg_train_2 = xgb.DMatrix(X_train_2, label=y_train_2)\n",
        "xg_test = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "params = {'objective': 'reg:linear', 'verbose': False}\n",
        "model_0 = xgb.train(params, xg_train_0, 30)\n",
        "model_1 = xgb.train(params, xg_train_1, 30)\n",
        "model_1.save_model('model_1.model')\n",
        "model_2_v1 = xgb.train(params, xg_train_2, 30)\n",
        "model_2_v2 = xgb.train(params, xg_train_2, 30, xgb_model=model_1)\n",
        "\n",
        "params.update({'process_type': 'update',\n",
        "               'updater'     : 'refresh',\n",
        "               'refresh_leaf': True})\n",
        "model_2_v2_update = xgb.train(params, xg_train_2, 30, xgb_model=model_1)\n",
        "\n",
        "print('full train\\t',mae(model_0.predict(xg_test), y_test)) # benchmark\n",
        "print('model 1 \\t',mae(model_1.predict(xg_test), y_test))  \n",
        "print('model 2 \\t',mae(model_2_v1.predict(xg_test), y_test))  # \"before\"\n",
        "print('model 1+2\\t',mae(model_2_v2.predict(xg_test), y_test))  # \"after\"\n",
        "print('model 1+update2\\t',mae(model_2_v2_update.predict(xg_test), y_test))  # \"after\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[03:11:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[03:11:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[03:11:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[03:11:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[03:11:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[03:11:36] WARNING: /workspace/src/learner.cc:194: DANGER AHEAD: You have manually specified `updater` parameter. The `tree_method` parameter will be ignored. Incorrect sequence of updaters will produce undefined behavior. For common uses, we recommend using `tree_method` parameter instead.\n",
            "full train\t 2.548246261320616\n",
            "model 1 \t 3.098096799850464\n",
            "model 2 \t 2.617744428860514\n",
            "model 1+2\t 2.7464016261853668\n",
            "model 1+update2\t 2.8126610558283955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMqFAjD2PPrn",
        "colab_type": "text"
      },
      "source": [
        "## XGB Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdcVZfojGzkV",
        "colab_type": "text"
      },
      "source": [
        "### Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVLtERR8PSiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnLxu_5VRpyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4RLSpuxG3uM",
        "colab_type": "text"
      },
      "source": [
        "### Get number of boosters by CV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIrUVkhdL66E",
        "colab_type": "text"
      },
      "source": [
        "xgb.cv performs cross-validation at each boosting iteration and thus returns the optimum number of trees required."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW8BZgH7-Cg3",
        "colab_type": "code",
        "outputId": "a8a3e498-6c7b-424d-ae29-8aa4c3193637",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "xgb1 = XGBClassifier(\n",
        "    learning_rate =0.1,\n",
        "    n_estimators=1000,\n",
        "    max_depth=5,\n",
        "    min_child_weight=1,\n",
        "    gamma=0,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    objective= 'multi:softprob',\n",
        "    num_class=3,\n",
        "    nthread=4,\n",
        "    scale_pos_weight=1,\n",
        "    seed=27)\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "xgb_param = xgb1.get_xgb_params()\n",
        "cvresult = xgb.cv(xgb_param, dtrain, \n",
        "                  num_boost_round = xgb1.get_params()['n_estimators'], \n",
        "                  nfold=5,\n",
        "                  metrics='mlogloss',\n",
        "                  early_stopping_rounds=50, \n",
        "                  stratified=True)\n",
        "\n",
        "cvresult"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train-mlogloss-mean</th>\n",
              "      <th>train-mlogloss-std</th>\n",
              "      <th>test-mlogloss-mean</th>\n",
              "      <th>test-mlogloss-std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.977897</td>\n",
              "      <td>0.002407</td>\n",
              "      <td>0.984724</td>\n",
              "      <td>0.009450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.872988</td>\n",
              "      <td>0.003070</td>\n",
              "      <td>0.886396</td>\n",
              "      <td>0.012001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.785642</td>\n",
              "      <td>0.003654</td>\n",
              "      <td>0.800829</td>\n",
              "      <td>0.010647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.708423</td>\n",
              "      <td>0.005110</td>\n",
              "      <td>0.725151</td>\n",
              "      <td>0.011139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.641874</td>\n",
              "      <td>0.006151</td>\n",
              "      <td>0.662517</td>\n",
              "      <td>0.011975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.582477</td>\n",
              "      <td>0.006543</td>\n",
              "      <td>0.608077</td>\n",
              "      <td>0.013172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.530642</td>\n",
              "      <td>0.006694</td>\n",
              "      <td>0.562257</td>\n",
              "      <td>0.016395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.484445</td>\n",
              "      <td>0.006883</td>\n",
              "      <td>0.520560</td>\n",
              "      <td>0.020744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.443772</td>\n",
              "      <td>0.006678</td>\n",
              "      <td>0.483261</td>\n",
              "      <td>0.020576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.407615</td>\n",
              "      <td>0.007206</td>\n",
              "      <td>0.451485</td>\n",
              "      <td>0.022554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.375168</td>\n",
              "      <td>0.007609</td>\n",
              "      <td>0.422796</td>\n",
              "      <td>0.024787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.346261</td>\n",
              "      <td>0.007600</td>\n",
              "      <td>0.396275</td>\n",
              "      <td>0.027021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.319355</td>\n",
              "      <td>0.006546</td>\n",
              "      <td>0.372993</td>\n",
              "      <td>0.029791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.295460</td>\n",
              "      <td>0.005932</td>\n",
              "      <td>0.353544</td>\n",
              "      <td>0.031727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.274107</td>\n",
              "      <td>0.006069</td>\n",
              "      <td>0.336912</td>\n",
              "      <td>0.033661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.254682</td>\n",
              "      <td>0.006052</td>\n",
              "      <td>0.319239</td>\n",
              "      <td>0.035084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.237113</td>\n",
              "      <td>0.005940</td>\n",
              "      <td>0.304256</td>\n",
              "      <td>0.035246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.221288</td>\n",
              "      <td>0.006386</td>\n",
              "      <td>0.290370</td>\n",
              "      <td>0.037163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.206624</td>\n",
              "      <td>0.006316</td>\n",
              "      <td>0.278674</td>\n",
              "      <td>0.037439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.193463</td>\n",
              "      <td>0.006930</td>\n",
              "      <td>0.267999</td>\n",
              "      <td>0.038549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.181286</td>\n",
              "      <td>0.006841</td>\n",
              "      <td>0.260009</td>\n",
              "      <td>0.040860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.170595</td>\n",
              "      <td>0.006447</td>\n",
              "      <td>0.252452</td>\n",
              "      <td>0.041312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.160096</td>\n",
              "      <td>0.006074</td>\n",
              "      <td>0.245681</td>\n",
              "      <td>0.042193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.150692</td>\n",
              "      <td>0.005999</td>\n",
              "      <td>0.239537</td>\n",
              "      <td>0.042814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.142128</td>\n",
              "      <td>0.006165</td>\n",
              "      <td>0.234199</td>\n",
              "      <td>0.044483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.134072</td>\n",
              "      <td>0.006110</td>\n",
              "      <td>0.228781</td>\n",
              "      <td>0.046630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.127046</td>\n",
              "      <td>0.006080</td>\n",
              "      <td>0.224853</td>\n",
              "      <td>0.047034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.120096</td>\n",
              "      <td>0.006071</td>\n",
              "      <td>0.221322</td>\n",
              "      <td>0.049238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.113914</td>\n",
              "      <td>0.005749</td>\n",
              "      <td>0.218443</td>\n",
              "      <td>0.050487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.108511</td>\n",
              "      <td>0.005665</td>\n",
              "      <td>0.216606</td>\n",
              "      <td>0.052603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.103520</td>\n",
              "      <td>0.005816</td>\n",
              "      <td>0.214205</td>\n",
              "      <td>0.053637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.098714</td>\n",
              "      <td>0.005715</td>\n",
              "      <td>0.211735</td>\n",
              "      <td>0.055586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.094222</td>\n",
              "      <td>0.005766</td>\n",
              "      <td>0.209545</td>\n",
              "      <td>0.057320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.090114</td>\n",
              "      <td>0.005590</td>\n",
              "      <td>0.207867</td>\n",
              "      <td>0.057911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.086580</td>\n",
              "      <td>0.005462</td>\n",
              "      <td>0.207497</td>\n",
              "      <td>0.060535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.083152</td>\n",
              "      <td>0.005461</td>\n",
              "      <td>0.206284</td>\n",
              "      <td>0.061176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.079859</td>\n",
              "      <td>0.005606</td>\n",
              "      <td>0.205773</td>\n",
              "      <td>0.062950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.076860</td>\n",
              "      <td>0.005587</td>\n",
              "      <td>0.204687</td>\n",
              "      <td>0.064416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.074164</td>\n",
              "      <td>0.005444</td>\n",
              "      <td>0.203970</td>\n",
              "      <td>0.067031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.071570</td>\n",
              "      <td>0.005403</td>\n",
              "      <td>0.202932</td>\n",
              "      <td>0.066797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.069316</td>\n",
              "      <td>0.005511</td>\n",
              "      <td>0.201780</td>\n",
              "      <td>0.067637</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    train-mlogloss-mean  ...  test-mlogloss-std\n",
              "0              0.977897  ...           0.009450\n",
              "1              0.872988  ...           0.012001\n",
              "2              0.785642  ...           0.010647\n",
              "3              0.708423  ...           0.011139\n",
              "4              0.641874  ...           0.011975\n",
              "5              0.582477  ...           0.013172\n",
              "6              0.530642  ...           0.016395\n",
              "7              0.484445  ...           0.020744\n",
              "8              0.443772  ...           0.020576\n",
              "9              0.407615  ...           0.022554\n",
              "10             0.375168  ...           0.024787\n",
              "11             0.346261  ...           0.027021\n",
              "12             0.319355  ...           0.029791\n",
              "13             0.295460  ...           0.031727\n",
              "14             0.274107  ...           0.033661\n",
              "15             0.254682  ...           0.035084\n",
              "16             0.237113  ...           0.035246\n",
              "17             0.221288  ...           0.037163\n",
              "18             0.206624  ...           0.037439\n",
              "19             0.193463  ...           0.038549\n",
              "20             0.181286  ...           0.040860\n",
              "21             0.170595  ...           0.041312\n",
              "22             0.160096  ...           0.042193\n",
              "23             0.150692  ...           0.042814\n",
              "24             0.142128  ...           0.044483\n",
              "25             0.134072  ...           0.046630\n",
              "26             0.127046  ...           0.047034\n",
              "27             0.120096  ...           0.049238\n",
              "28             0.113914  ...           0.050487\n",
              "29             0.108511  ...           0.052603\n",
              "30             0.103520  ...           0.053637\n",
              "31             0.098714  ...           0.055586\n",
              "32             0.094222  ...           0.057320\n",
              "33             0.090114  ...           0.057911\n",
              "34             0.086580  ...           0.060535\n",
              "35             0.083152  ...           0.061176\n",
              "36             0.079859  ...           0.062950\n",
              "37             0.076860  ...           0.064416\n",
              "38             0.074164  ...           0.067031\n",
              "39             0.071570  ...           0.066797\n",
              "40             0.069316  ...           0.067637\n",
              "\n",
              "[41 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfVrtLQ2BOnv",
        "colab_type": "code",
        "outputId": "5635792f-88ec-4037-c818-2f46bf9b68d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(cvresult.shape)\n",
        "xgb1.set_params(n_estimators=cvresult.shape[0])\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(xgb1, X_train, y_train, cv=5)\n",
        "\n",
        "print(\"Accuracy of cross validation(train): %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "\n",
        "scores = cross_val_score(xgb1, X_test, y_test, cv=5)\n",
        "print(\"Accuracy of cross validation(test): %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(41, 4)\n",
            "Accuracy of cross validation(train): 0.9500 (+/- 0.08)\n",
            "Accuracy of cross validation(test): 0.9048 (+/- 0.16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awMOAKTBFwyi",
        "colab_type": "code",
        "outputId": "b66d7a7e-1aa1-483e-ca7f-ce84b0cb2d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "xgb1.fit(X_train, y_train)\n",
        "print(xgb1.feature_importances_)\n",
        "print(xgb1.get_booster().get_fscore())\n",
        "\n",
        "# importance_type = ['weight', 'gain', 'cover', 'total_gain', 'total_cover']\n",
        "print(xgb1.get_booster().get_score(importance_type='weight'))\n",
        "\n",
        "from xgboost import plot_importance\n",
        "plot_importance(xgb1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.02989605 0.04874194 0.51202303 0.409339  ]\n",
            "{'f2': 174, 'f3': 110, 'f0': 53, 'f1': 60}\n",
            "{'f2': 174, 'f3': 110, 'f0': 53, 'f1': 60}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f61000ad400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEWCAYAAACOv5f1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luqAEOFxP8-Y",
        "colab_type": "text"
      },
      "source": [
        "### Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmYTz_ldWkTS",
        "colab_type": "code",
        "outputId": "c11437bb-8d07-441b-ee80-4190fcda308c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "import sklearn\n",
        "sorted(sklearn.metrics.SCORERS.keys())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['accuracy',\n",
              " 'adjusted_mutual_info_score',\n",
              " 'adjusted_rand_score',\n",
              " 'average_precision',\n",
              " 'balanced_accuracy',\n",
              " 'brier_score_loss',\n",
              " 'completeness_score',\n",
              " 'explained_variance',\n",
              " 'f1',\n",
              " 'f1_macro',\n",
              " 'f1_micro',\n",
              " 'f1_samples',\n",
              " 'f1_weighted',\n",
              " 'fowlkes_mallows_score',\n",
              " 'homogeneity_score',\n",
              " 'jaccard',\n",
              " 'jaccard_macro',\n",
              " 'jaccard_micro',\n",
              " 'jaccard_samples',\n",
              " 'jaccard_weighted',\n",
              " 'max_error',\n",
              " 'mutual_info_score',\n",
              " 'neg_log_loss',\n",
              " 'neg_mean_absolute_error',\n",
              " 'neg_mean_squared_error',\n",
              " 'neg_mean_squared_log_error',\n",
              " 'neg_median_absolute_error',\n",
              " 'normalized_mutual_info_score',\n",
              " 'precision',\n",
              " 'precision_macro',\n",
              " 'precision_micro',\n",
              " 'precision_samples',\n",
              " 'precision_weighted',\n",
              " 'r2',\n",
              " 'recall',\n",
              " 'recall_macro',\n",
              " 'recall_micro',\n",
              " 'recall_samples',\n",
              " 'recall_weighted',\n",
              " 'roc_auc',\n",
              " 'v_measure_score']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPyJH484SlLG",
        "colab_type": "text"
      },
      "source": [
        "If a best param is on the boundary of the testing interval, we should try another interval to cover it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyZ0QGsJR9vT",
        "colab_type": "code",
        "outputId": "4577680b-5781-47f1-e8be-16195ed769ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "param_test1 = {\n",
        "    'max_depth':range(3,10,2),\n",
        "    'min_child_weight':range(1,6,2)}\n",
        "\n",
        "gsearch1 = GridSearchCV(estimator = XGBClassifier(\n",
        "    learning_rate=0.1, n_estimators=41, max_depth=5,\n",
        "    min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
        "    objective= 'multi:softprob', nthread=4, scale_pos_weight=1, seed=27), \n",
        "    param_grid = param_test1, scoring='accuracy', n_jobs=4, iid=False, cv=5)\n",
        "\n",
        "gsearch1.fit(X_train, y_train)\n",
        "gsearch1.best_params_, gsearch1.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'max_depth': 3, 'min_child_weight': 1}, 0.9499710144927537)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu9F8BLoTcHe",
        "colab_type": "code",
        "outputId": "3bce2c19-dc31-42d4-ce68-5f3b9beefb61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "param_test2 = {\n",
        "    'max_depth':[1, 2, 3, 4],\n",
        "    'min_child_weight':[1, 2, 3]\n",
        "}\n",
        "gsearch2 = GridSearchCV(estimator = XGBClassifier(\n",
        "    learning_rate=0.1, n_estimators=41, max_depth=3,\n",
        "    min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
        "    objective= 'multi:softprob', nthread=4, scale_pos_weight=1, seed=27), \n",
        "    param_grid = param_test2, scoring='accuracy', n_jobs=4,iid=False, cv=5)\n",
        "\n",
        "gsearch2.fit(X_train, y_train)\n",
        "gsearch2.best_params_, gsearch2.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'max_depth': 1, 'min_child_weight': 1}, 0.9583043478260869)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7B_ukwu28kM",
        "colab_type": "code",
        "outputId": "f537357e-8d65-4b4c-85cc-4f80ff5ff309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "param_test3 = {\n",
        " 'gamma':[i/10.0 for i in range(0,5)]\n",
        "}\n",
        "gsearch2 = GridSearchCV(estimator = XGBClassifier(\n",
        "    learning_rate=0.1, n_estimators=41, max_depth=1,\n",
        "    min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
        "    objective= 'multi:softprob', nthread=4, scale_pos_weight=1, seed=27), \n",
        "    param_grid = param_test3, scoring='accuracy', n_jobs=4,iid=False, cv=5)\n",
        "\n",
        "gsearch2.fit(X_train, y_train)\n",
        "gsearch2.best_params_, gsearch2.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'gamma': 0.0}, 0.9583043478260869)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_4BeVtyYRrv",
        "colab_type": "text"
      },
      "source": [
        "Before proceeding, a good idea would be to re-calibrate the number of boosting rounds for the updated parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9t3xN15Xnxj",
        "colab_type": "code",
        "outputId": "021f29e5-9153-4994-8070-d47e474c3156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "xgb2 = XGBClassifier(\n",
        "    learning_rate=0.1,\n",
        "    n_estimators=1000,\n",
        "    max_depth=1,\n",
        "    min_child_weight=1,\n",
        "    gamma=0,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    objective= 'multi:softprob',\n",
        "    num_class=3,\n",
        "    nthread=4,\n",
        "    scale_pos_weight=1,\n",
        "    seed=27)\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "xgb_param = xgb2.get_xgb_params()\n",
        "cvresult = xgb.cv(xgb_param, dtrain, \n",
        "                  num_boost_round = xgb1.get_params()['n_estimators'], \n",
        "                  nfold=5,\n",
        "                  metrics='mlogloss',\n",
        "                  early_stopping_rounds=50, \n",
        "                  stratified=True)\n",
        "\n",
        "print(\"best number of boosting rounds: \", cvresult.shape[0])\n",
        "xgb2.set_params(n_estimators=cvresult.shape[0])\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(xgb2, X_train, y_train, cv=5)\n",
        "print(\"Accuracy of cross validation(train): %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "scores = cross_val_score(xgb2, X_test, y_test, cv=5)\n",
        "print(\"Accuracy of cross validation(test): %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best number of boosting rounds:  41\n",
            "Accuracy of cross validation(train): 0.9583 (+/- 0.09)\n",
            "Accuracy of cross validation(test): 0.9048 (+/- 0.16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a9XSkgUY35F",
        "colab_type": "code",
        "outputId": "a53f559f-8013-4ae9-817b-e925b95800f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "param_test4 = {\n",
        "    'subsample':[i/10.0 for i in range(6,10)],\n",
        "    'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
        "}\n",
        "gsearch4 = GridSearchCV(estimator = XGBClassifier(\n",
        "    learning_rate=0.1, n_estimators=72, max_depth=1,\n",
        "    min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
        "    objective= 'multi:softprob', nthread=4, scale_pos_weight=1, seed=27), \n",
        "    param_grid = param_test4, scoring='accuracy', n_jobs=4,iid=False, cv=5)\n",
        "\n",
        "gsearch4.fit(X_train, y_train)\n",
        "gsearch4.best_params_, gsearch2.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'colsample_bytree': 0.6, 'subsample': 0.6}, 0.9583043478260869)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekSly8cNapm0",
        "colab_type": "code",
        "outputId": "22f37de9-adde-4f02-b3a3-55619f47353a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "param_test5 = {\n",
        "    'subsample':[i/100.0 for i in range(55,65,5)],\n",
        "    'colsample_bytree':[i/100.0 for i in range(55,65,5)]\n",
        "}\n",
        "gsearch5 = GridSearchCV(estimator = XGBClassifier(\n",
        "    learning_rate=0.1, n_estimators=72, max_depth=1,\n",
        "    min_child_weight=1, gamma=0, subsample=0.6, colsample_bytree=0.6,\n",
        "    objective= 'multi:softprob', nthread=4, scale_pos_weight=1, seed=27), \n",
        "    param_grid = param_test5, scoring='accuracy', n_jobs=4,iid=False, cv=5)\n",
        "\n",
        "gsearch5.fit(X_train, y_train)\n",
        "gsearch5.best_params_, gsearch5.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'colsample_bytree': 0.55, 'subsample': 0.6}, 0.9583043478260869)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnUad05UcmbN",
        "colab_type": "text"
      },
      "source": [
        "Tuning Regularization Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y91yeNLc3oS",
        "colab_type": "code",
        "outputId": "1a7f54ae-c6ea-4aeb-879b-9e78e4b08ef6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "param_test6 = {\n",
        "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100],\n",
        "    'reg_lambda':[1e-5, 1e-2, 0.1, 1, 100]\n",
        "}\n",
        "\n",
        "gsearch6 = GridSearchCV(estimator = XGBClassifier(\n",
        "    learning_rate=0.1, n_estimators=72, max_depth=1,\n",
        "    min_child_weight=1, gamma=0, subsample=0.6, colsample_bytree=0.55,\n",
        "    objective= 'multi:softprob', nthread=4, scale_pos_weight=1, seed=27), \n",
        "    param_grid = param_test6, scoring='accuracy', n_jobs=4,iid=False, cv=5)\n",
        "\n",
        "gsearch6.fit(X_train, y_train)\n",
        "gsearch6.best_params_, gsearch6.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'reg_alpha': 1e-05, 'reg_lambda': 1e-05}, 0.9663043478260869)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLoWQqepdF_b",
        "colab_type": "code",
        "outputId": "1a857db1-a620-47c7-e6d8-3f27436367f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "param_test7 = {\n",
        "    'reg_alpha':[0, 1e-6, 5*1e-6, 1e-5, 5*1e-5],\n",
        "    'reg_lambda':[0, 1e-6, 5*1e-6, 1e-5, 5*1e-5]\n",
        "}\n",
        "\n",
        "gsearch7 = GridSearchCV(estimator = XGBClassifier(\n",
        "    learning_rate=0.1, n_estimators=72, max_depth=1,\n",
        "    min_child_weight=1, gamma=0, subsample=0.6, colsample_bytree=0.55,\n",
        "    objective= 'multi:softprob', nthread=4, scale_pos_weight=1, seed=27), \n",
        "    param_grid = param_test7, scoring='accuracy', n_jobs=4,iid=False, cv=5)\n",
        "\n",
        "gsearch7.fit(X_train, y_train)\n",
        "gsearch7.best_params_, gsearch7.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'reg_alpha': 0, 'reg_lambda': 0}, 0.9663043478260869)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHzXtd-BdX5k",
        "colab_type": "code",
        "outputId": "05a88e89-677b-466e-b4eb-be81f63e0a1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "xgb3 = XGBClassifier(\n",
        "    learning_rate=0.1,\n",
        "    n_estimators=1000,\n",
        "    max_depth=1,\n",
        "    min_child_weight=1,\n",
        "    gamma=0,\n",
        "    subsample=0.6,\n",
        "    colsample_bytree=0.55,\n",
        "    reg_alpha=0,\n",
        "    reg_lambda=0,\n",
        "    objective= 'multi:softprob',\n",
        "    num_class=3,\n",
        "    nthread=4,\n",
        "    scale_pos_weight=1,\n",
        "    seed=27)\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "xgb_param = xgb3.get_xgb_params()\n",
        "cvresult = xgb.cv(xgb_param, dtrain, \n",
        "                  num_boost_round = xgb1.get_params()['n_estimators'], \n",
        "                  nfold=5,\n",
        "                  metrics='mlogloss',\n",
        "                  early_stopping_rounds=50, \n",
        "                  stratified=True)\n",
        "\n",
        "print(\"best number of boosting rounds: \", cvresult.shape[0])\n",
        "xgb3.set_params(n_estimators=cvresult.shape[0])\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(xgb3, X_train, y_train, cv=5)\n",
        "print(\"Accuracy of cross validation(train): %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "scores = cross_val_score(xgb3, X_test, y_test, cv=5)\n",
        "print(\"Accuracy of cross validation(test): %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best number of boosting rounds:  41\n",
            "Accuracy of cross validation(train): 0.9663 (+/- 0.10)\n",
            "Accuracy of cross validation(test): 0.9667 (+/- 0.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "518tSMCkg-Va",
        "colab_type": "text"
      },
      "source": [
        "Reducing Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh1MIEp_g-8W",
        "colab_type": "code",
        "outputId": "640f3f54-dcae-4805-e54a-581f0ecb18ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "final_params = {\n",
        "    'learning_rate': 0.08,\n",
        "    'n_estimators': 1000,\n",
        "    'max_depth': 1,\n",
        "    'min_child_weight': 1,\n",
        "    'gamma': 0,\n",
        "    'subsample': 0.6,\n",
        "    'colsample_bytree': 0.55,\n",
        "    'reg_alpha': 0,\n",
        "    'reg_lambda': 0,\n",
        "    'objective': 'multi:softmax',\n",
        "    'num_class': 3,\n",
        "    'nthread': 4,\n",
        "    'scale_pos_weight': 1,\n",
        "    'seed': 27 }\n",
        "\n",
        "xgb4 = XGBClassifier(**final_params)\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "xgb_param = xgb4.get_xgb_params()\n",
        "cvresult = xgb.cv(xgb_param, dtrain, \n",
        "                  num_boost_round = xgb1.get_params()['n_estimators'], \n",
        "                  nfold=5,\n",
        "                  metrics='mlogloss',\n",
        "                  early_stopping_rounds=50, \n",
        "                  stratified=True)\n",
        "\n",
        "print(\"best number of boosting rounds: \", cvresult.shape[0])\n",
        "xgb4.set_params(n_estimators=cvresult.shape[0])\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(xgb4, X_train, y_train, cv=5)\n",
        "print(\"Accuracy of cross validation(train): %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "scores = cross_val_score(xgb4, X_test, y_test, cv=5)\n",
        "print(\"Accuracy of cross validation(test): %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best number of boosting rounds:  41\n",
            "Accuracy of cross validation(train): 0.9663 (+/- 0.10)\n",
            "Accuracy of cross validation(test): 0.9333 (+/- 0.16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UllavcEqgmj_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "4089ee8e-6ff1-4cf0-d474-0b49d131c2d4"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "xgb4.fit(X_train, y_train)\n",
        "predict_y = xgb4.predict(X_test)\n",
        "print(classification_report(y_test, \n",
        "                            predict_y, \n",
        "                            target_names=['setosa', 'versicolor', 'virginica']))\n",
        "print(confusion_matrix(y_test, predict_y))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      1.00      1.00         9\n",
            "   virginica       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "[[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siGlIhEyg0BL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}