{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xgboost.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "9UpYPY6q_ccJ",
        "hMKSl_al-L05",
        "YMqFAjD2PPrn",
        "MdcVZfojGzkV",
        "P4RLSpuxG3uM",
        "luqAEOFxP8-Y"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minghsu0107/ML/blob/master/machine-learning/xgboost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UpYPY6q_ccJ",
        "colab_type": "text"
      },
      "source": [
        "## Play with Iris Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j57fHMjvWfkg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0294193-f064-41bd-80bb-791a842d4d20"
      },
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "X.shape"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB2IaXgb_ggX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7134ce44-bc41-4911-e956-f78ffc8ec38d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train.shape, y_train.shape"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((120, 4), (120,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pD3P-AN-7AU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlIjD6ErBHtj",
        "colab_type": "text"
      },
      "source": [
        "If you want to use svmlight for less memory consumption, first dump the numpy array into svmlight format and then just pass the filename to DMatrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrSjUINbATwv",
        "colab_type": "code",
        "outputId": "efa86782-839a-44b1-bc89-dea0014f22b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.datasets import dump_svmlight_file\n",
        "\n",
        "dump_svmlight_file(X_train, y_train, 'dtrain.svm', zero_based=True)\n",
        "dump_svmlight_file(X_test, y_test, 'dtest.svm', zero_based=True)\n",
        "dtrain_svm = xgb.DMatrix('dtrain.svm')\n",
        "dtest_svm = xgb.DMatrix('dtest.svm')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[02:44:26] 120x4 matrix with 480 entries loaded from dtrain.svm\n",
            "[02:44:26] 30x4 matrix with 120 entries loaded from dtest.svm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zvOzymeCgX7",
        "colab_type": "text"
      },
      "source": [
        "Generally try with eta 0.1, 0.2, 0.3, max_depth in range of 2 to 10 and num_round around few hundred."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mUApdpOAeCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param = {\n",
        "    'booster': 'gbtree',\n",
        "    'max_depth': 3,  # the maximum depth of each tree\n",
        "    'eta': 0.3,  # the training step for each iteration\n",
        "    'silent': 1,  # logging mode - quiet\n",
        "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
        "    'num_class': 3}  # the number of classes that exist in this datset\n",
        "num_round = 20  # the number of training iterations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VpFZ3I_CVtr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bst = xgb.train(param, dtrain_svm, num_round)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nYhSRT3Cnie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bst.dump_model('dump.raw.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QYM5jRjCwPM",
        "colab_type": "code",
        "outputId": "3255a0e2-075e-4991-80ac-b02e6e129f2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "preds = bst.predict(dtest)\n",
        "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "best_preds"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
              "       0, 2, 2, 2, 2, 2, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15pfJ9dRFCEV",
        "colab_type": "code",
        "outputId": "747f261e-0846-4bd1-f032-664fc9da8058",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "print(precision_score(y_test, best_preds, average='macro'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgJ933pd53Gm",
        "colab_type": "text"
      },
      "source": [
        "We  can save the model for further usage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQUjjVWnFsxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bst.save_model('iris_bst.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUtfr2kS3lHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = xgb.Booster()\n",
        "clf.load_model('iris_bst.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9gEgMux33Q5",
        "colab_type": "code",
        "outputId": "9f4e6046-5dc9-4044-fb6c-484f669a5297",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "clf.predict(dtest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00563804, 0.97755206, 0.01680986],\n",
              "       [0.98254657, 0.01395846, 0.00349498],\n",
              "       [0.0036375 , 0.00615226, 0.9902103 ],\n",
              "       [0.00564738, 0.97917044, 0.0151822 ],\n",
              "       [0.00540075, 0.93640935, 0.0581899 ],\n",
              "       [0.98607963, 0.0104128 , 0.00350755],\n",
              "       [0.00438964, 0.99041265, 0.0051977 ],\n",
              "       [0.0156953 , 0.06653062, 0.91777414],\n",
              "       [0.0063378 , 0.94877166, 0.04489056],\n",
              "       [0.00438964, 0.99041265, 0.0051977 ],\n",
              "       [0.01785045, 0.07566603, 0.9064836 ],\n",
              "       [0.99054164, 0.00561866, 0.00383973],\n",
              "       [0.98254657, 0.01395846, 0.00349498],\n",
              "       [0.990855  , 0.00562044, 0.00352453],\n",
              "       [0.990855  , 0.00562044, 0.00352453],\n",
              "       [0.00435676, 0.9863815 , 0.00926175],\n",
              "       [0.0028351 , 0.00545694, 0.991708  ],\n",
              "       [0.00506935, 0.98753244, 0.00739827],\n",
              "       [0.00435527, 0.98265946, 0.01298527],\n",
              "       [0.00283684, 0.00484793, 0.9923152 ],\n",
              "       [0.990855  , 0.00562044, 0.00352453],\n",
              "       [0.01177546, 0.08546326, 0.90276134],\n",
              "       [0.990855  , 0.00562044, 0.00352453],\n",
              "       [0.00283684, 0.00484793, 0.9923152 ],\n",
              "       [0.00561747, 0.01081239, 0.98357016],\n",
              "       [0.00363441, 0.00699543, 0.9893701 ],\n",
              "       [0.0036375 , 0.00615226, 0.9902103 ],\n",
              "       [0.00561747, 0.01081239, 0.98357016],\n",
              "       [0.99054164, 0.00561866, 0.00383973],\n",
              "       [0.990855  , 0.00562044, 0.00352453]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF_pDmNY4Bqd",
        "colab_type": "code",
        "outputId": "7bbf3143-5c61-4840-9a3d-f5ceef94d6e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "from xgboost import plot_importance\n",
        "print(clf.get_fscore())\n",
        "plot_importance(clf)"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'f2': 91, 'f3': 44, 'f0': 19, 'f1': 18}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f40794910f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 248
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtMAAAEWCAYAAACkORurAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUkn/H1N7P3mD50hrAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNdN7goXMzt5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "outputId": "55d5f162-130c-47e6-876b-c38cf1ced3fb"
      },
      "source": [
        "dir(clf)"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__copy__',\n",
              " '__deepcopy__',\n",
              " '__del__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_validate_features',\n",
              " 'attr',\n",
              " 'attributes',\n",
              " 'boost',\n",
              " 'booster',\n",
              " 'copy',\n",
              " 'dump_model',\n",
              " 'eval',\n",
              " 'eval_set',\n",
              " 'feature_names',\n",
              " 'feature_types',\n",
              " 'get_dump',\n",
              " 'get_fscore',\n",
              " 'get_score',\n",
              " 'get_split_value_histogram',\n",
              " 'handle',\n",
              " 'load_model',\n",
              " 'load_rabit_checkpoint',\n",
              " 'predict',\n",
              " 'save_model',\n",
              " 'save_rabit_checkpoint',\n",
              " 'save_raw',\n",
              " 'set_attr',\n",
              " 'set_param',\n",
              " 'trees_to_dataframe',\n",
              " 'update']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3eZgmVX6jvd",
        "colab_type": "text"
      },
      "source": [
        "We can also continue training on the existed model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VFdgi8k5DbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bst = xgb.train(param, dtest, num_round, xgb_model='iris_bst.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw5b4hda66Ox",
        "colab_type": "code",
        "outputId": "c0bf9f67-fe30-4cfc-8f62-05911d8c610f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "bst.predict(dtest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00626042, 0.97150415, 0.02223538],\n",
              "       [0.9833303 , 0.01250299, 0.00416675],\n",
              "       [0.00305996, 0.00463209, 0.9923079 ],\n",
              "       [0.00627413, 0.9736327 , 0.02009312],\n",
              "       [0.00591656, 0.9181438 , 0.07593963],\n",
              "       [0.98649627, 0.00932354, 0.00418016],\n",
              "       [0.0048936 , 0.98820364, 0.00690268],\n",
              "       [0.01343146, 0.05095716, 0.93561137],\n",
              "       [0.00697244, 0.93419635, 0.05883117],\n",
              "       [0.0048936 , 0.98820364, 0.00690268],\n",
              "       [0.01531663, 0.05810924, 0.9265741 ],\n",
              "       [0.9903985 , 0.00502806, 0.00457345],\n",
              "       [0.9833303 , 0.01250299, 0.00416675],\n",
              "       [0.9907718 , 0.00502995, 0.00419828],\n",
              "       [0.9907718 , 0.00502995, 0.00419828],\n",
              "       [0.00485046, 0.9828661 , 0.01228339],\n",
              "       [0.00238424, 0.00410734, 0.99350846],\n",
              "       [0.0056468 , 0.984536  , 0.00981717],\n",
              "       [0.00484286, 0.97795653, 0.01720059],\n",
              "       [0.00238534, 0.0036484 , 0.9939663 ],\n",
              "       [0.9907718 , 0.00502995, 0.00419828],\n",
              "       [0.01011908, 0.06573138, 0.9241496 ],\n",
              "       [0.9907718 , 0.00502995, 0.00419828],\n",
              "       [0.00238534, 0.0036484 , 0.9939663 ],\n",
              "       [0.00473257, 0.00815282, 0.98711467],\n",
              "       [0.003058  , 0.00526804, 0.991674  ],\n",
              "       [0.00305996, 0.00463209, 0.9923079 ],\n",
              "       [0.00473257, 0.00815282, 0.98711467],\n",
              "       [0.9903985 , 0.00502806, 0.00457345],\n",
              "       [0.9907718 , 0.00502995, 0.00419828]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMKSl_al-L05",
        "colab_type": "text"
      },
      "source": [
        "## Incremental Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYgJAolF-R04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.metrics import mean_absolute_error as mae"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg36NSCwAMP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "boston = load_boston()\n",
        "features = boston.feature_names\n",
        "X = boston.data\n",
        "y = boston.target\n",
        "\n",
        "X=pd.DataFrame(X,columns=features)\n",
        "y = pd.Series(y, index=X.index)\n",
        "\n",
        "# split data into training and testing sets\n",
        "# n_splits = 1: split for one time\n",
        "rs = ShuffleSplit(test_size=0.3, n_splits=1, random_state=10)\n",
        "for train_idx, test_idx in rs.split(X):  # this looks silly\n",
        "    pass\n",
        "\n",
        "train_split = round(len(train_idx) / 2)\n",
        "train1_idx = train_idx[:train_split]\n",
        "train2_idx = train_idx[train_split:]\n",
        "\n",
        "X_train = X.loc[train_idx]\n",
        "X_train_1 = X.loc[train1_idx]\n",
        "X_train_2 = X.loc[train2_idx]\n",
        "X_test = X.loc[test_idx]\n",
        "\n",
        "y_train = y.loc[train_idx]\n",
        "y_train_1 = y.loc[train1_idx]\n",
        "y_train_2 = y.loc[train2_idx]\n",
        "y_test = y.loc[test_idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r5xId8uAfbe",
        "colab_type": "code",
        "outputId": "b587fbc4-d812-4677-9e7d-3eeaf3cecdcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "xg_train_0 = xgb.DMatrix(X_train, label=y_train)\n",
        "xg_train_1 = xgb.DMatrix(X_train_1, label=y_train_1)\n",
        "xg_train_2 = xgb.DMatrix(X_train_2, label=y_train_2)\n",
        "xg_test = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "params = {'objective': 'reg:linear', 'verbose': False}\n",
        "model_0 = xgb.train(params, xg_train_0, 30)\n",
        "model_1 = xgb.train(params, xg_train_1, 30)\n",
        "model_1.save_model('model_1.model')\n",
        "model_2_v1 = xgb.train(params, xg_train_2, 30)\n",
        "model_2_v2 = xgb.train(params, xg_train_2, 30, xgb_model=model_1)\n",
        "\n",
        "params.update({'process_type': 'update',\n",
        "               'updater'     : 'refresh',\n",
        "               'refresh_leaf': True})\n",
        "model_2_v2_update = xgb.train(params, xg_train_2, 30, xgb_model=model_1)\n",
        "\n",
        "print('full train\\t',mae(model_0.predict(xg_test), y_test)) # benchmark\n",
        "print('model 1 \\t',mae(model_1.predict(xg_test), y_test))  \n",
        "print('model 2 \\t',mae(model_2_v1.predict(xg_test), y_test))  # \"before\"\n",
        "print('model 1+2\\t',mae(model_2_v2.predict(xg_test), y_test))  # \"after\"\n",
        "print('model 1+update2\\t',mae(model_2_v2_update.predict(xg_test), y_test))  # \"after\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[02:44:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[02:44:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[02:44:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[02:44:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[02:44:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[02:44:26] WARNING: /workspace/src/learner.cc:194: DANGER AHEAD: You have manually specified `updater` parameter. The `tree_method` parameter will be ignored. Incorrect sequence of updaters will produce undefined behavior. For common uses, we recommend using `tree_method` parameter instead.\n",
            "full train\t 2.548246261320616\n",
            "model 1 \t 3.098096799850464\n",
            "model 2 \t 2.617744428860514\n",
            "model 1+2\t 2.7464016261853668\n",
            "model 1+update2\t 2.8126610558283955\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rm_OVN2BTnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMqFAjD2PPrn",
        "colab_type": "text"
      },
      "source": [
        "## XGB Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdcVZfojGzkV",
        "colab_type": "text"
      },
      "source": [
        "### Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVLtERR8PSiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnLxu_5VRpyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4RLSpuxG3uM",
        "colab_type": "text"
      },
      "source": [
        "### Get number of boosters by CV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIrUVkhdL66E",
        "colab_type": "text"
      },
      "source": [
        "xgb.cv performs cross-validation at each boosting iteration and thus returns the optimum number of trees required."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW8BZgH7-Cg3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8611079c-11d3-4502-bc7d-862dde3a730f"
      },
      "source": [
        "xgb1 = XGBClassifier(\n",
        "    learning_rate =0.1,\n",
        "    n_estimators=1000,\n",
        "    max_depth=5,\n",
        "    min_child_weight=1,\n",
        "    gamma=0,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    objective= 'multi:softprob',\n",
        "    num_class=3,\n",
        "    nthread=4,\n",
        "    scale_pos_weight=1,\n",
        "    seed=27)\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "xgb_param = xgb1.get_xgb_params()\n",
        "cvresult = xgb.cv(xgb_param, dtrain, \n",
        "                  num_boost_round = xgb1.get_params()['n_estimators'], \n",
        "                  nfold=5,\n",
        "                  metrics='mlogloss',\n",
        "                  early_stopping_rounds=50, \n",
        "                  stratified=True)\n",
        "\n",
        "cvresult"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train-mlogloss-mean</th>\n",
              "      <th>train-mlogloss-std</th>\n",
              "      <th>test-mlogloss-mean</th>\n",
              "      <th>test-mlogloss-std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.977897</td>\n",
              "      <td>0.002407</td>\n",
              "      <td>0.984724</td>\n",
              "      <td>0.009450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.872988</td>\n",
              "      <td>0.003070</td>\n",
              "      <td>0.886396</td>\n",
              "      <td>0.012001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.785642</td>\n",
              "      <td>0.003654</td>\n",
              "      <td>0.800829</td>\n",
              "      <td>0.010647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.708423</td>\n",
              "      <td>0.005110</td>\n",
              "      <td>0.725151</td>\n",
              "      <td>0.011139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.641874</td>\n",
              "      <td>0.006151</td>\n",
              "      <td>0.662517</td>\n",
              "      <td>0.011975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.582477</td>\n",
              "      <td>0.006543</td>\n",
              "      <td>0.608077</td>\n",
              "      <td>0.013172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.530642</td>\n",
              "      <td>0.006694</td>\n",
              "      <td>0.562257</td>\n",
              "      <td>0.016395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.484445</td>\n",
              "      <td>0.006883</td>\n",
              "      <td>0.520560</td>\n",
              "      <td>0.020744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.443772</td>\n",
              "      <td>0.006678</td>\n",
              "      <td>0.483261</td>\n",
              "      <td>0.020576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.407615</td>\n",
              "      <td>0.007206</td>\n",
              "      <td>0.451485</td>\n",
              "      <td>0.022554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.375168</td>\n",
              "      <td>0.007609</td>\n",
              "      <td>0.422796</td>\n",
              "      <td>0.024787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.346261</td>\n",
              "      <td>0.007600</td>\n",
              "      <td>0.396275</td>\n",
              "      <td>0.027021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.319355</td>\n",
              "      <td>0.006546</td>\n",
              "      <td>0.372993</td>\n",
              "      <td>0.029791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.295460</td>\n",
              "      <td>0.005932</td>\n",
              "      <td>0.353544</td>\n",
              "      <td>0.031727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.274107</td>\n",
              "      <td>0.006069</td>\n",
              "      <td>0.336912</td>\n",
              "      <td>0.033661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.254682</td>\n",
              "      <td>0.006052</td>\n",
              "      <td>0.319239</td>\n",
              "      <td>0.035084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.237113</td>\n",
              "      <td>0.005940</td>\n",
              "      <td>0.304256</td>\n",
              "      <td>0.035246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.221288</td>\n",
              "      <td>0.006386</td>\n",
              "      <td>0.290370</td>\n",
              "      <td>0.037163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.206624</td>\n",
              "      <td>0.006316</td>\n",
              "      <td>0.278674</td>\n",
              "      <td>0.037439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.193463</td>\n",
              "      <td>0.006930</td>\n",
              "      <td>0.267999</td>\n",
              "      <td>0.038549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.181286</td>\n",
              "      <td>0.006841</td>\n",
              "      <td>0.260009</td>\n",
              "      <td>0.040860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.170595</td>\n",
              "      <td>0.006447</td>\n",
              "      <td>0.252452</td>\n",
              "      <td>0.041312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.160096</td>\n",
              "      <td>0.006074</td>\n",
              "      <td>0.245681</td>\n",
              "      <td>0.042193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.150692</td>\n",
              "      <td>0.005999</td>\n",
              "      <td>0.239537</td>\n",
              "      <td>0.042814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.142128</td>\n",
              "      <td>0.006165</td>\n",
              "      <td>0.234199</td>\n",
              "      <td>0.044483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.134072</td>\n",
              "      <td>0.006110</td>\n",
              "      <td>0.228781</td>\n",
              "      <td>0.046630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.127046</td>\n",
              "      <td>0.006080</td>\n",
              "      <td>0.224853</td>\n",
              "      <td>0.047034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.120096</td>\n",
              "      <td>0.006071</td>\n",
              "      <td>0.221322</td>\n",
              "      <td>0.049238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.113914</td>\n",
              "      <td>0.005749</td>\n",
              "      <td>0.218443</td>\n",
              "      <td>0.050487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.108511</td>\n",
              "      <td>0.005665</td>\n",
              "      <td>0.216606</td>\n",
              "      <td>0.052603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.103520</td>\n",
              "      <td>0.005816</td>\n",
              "      <td>0.214205</td>\n",
              "      <td>0.053637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.098714</td>\n",
              "      <td>0.005715</td>\n",
              "      <td>0.211735</td>\n",
              "      <td>0.055586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.094222</td>\n",
              "      <td>0.005766</td>\n",
              "      <td>0.209545</td>\n",
              "      <td>0.057320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.090114</td>\n",
              "      <td>0.005590</td>\n",
              "      <td>0.207867</td>\n",
              "      <td>0.057911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.086580</td>\n",
              "      <td>0.005462</td>\n",
              "      <td>0.207497</td>\n",
              "      <td>0.060535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.083152</td>\n",
              "      <td>0.005461</td>\n",
              "      <td>0.206284</td>\n",
              "      <td>0.061176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.079859</td>\n",
              "      <td>0.005606</td>\n",
              "      <td>0.205773</td>\n",
              "      <td>0.062950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.076860</td>\n",
              "      <td>0.005587</td>\n",
              "      <td>0.204687</td>\n",
              "      <td>0.064416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.074164</td>\n",
              "      <td>0.005444</td>\n",
              "      <td>0.203970</td>\n",
              "      <td>0.067031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.071570</td>\n",
              "      <td>0.005403</td>\n",
              "      <td>0.202932</td>\n",
              "      <td>0.066797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.069316</td>\n",
              "      <td>0.005511</td>\n",
              "      <td>0.201780</td>\n",
              "      <td>0.067637</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    train-mlogloss-mean  ...  test-mlogloss-std\n",
              "0              0.977897  ...           0.009450\n",
              "1              0.872988  ...           0.012001\n",
              "2              0.785642  ...           0.010647\n",
              "3              0.708423  ...           0.011139\n",
              "4              0.641874  ...           0.011975\n",
              "5              0.582477  ...           0.013172\n",
              "6              0.530642  ...           0.016395\n",
              "7              0.484445  ...           0.020744\n",
              "8              0.443772  ...           0.020576\n",
              "9              0.407615  ...           0.022554\n",
              "10             0.375168  ...           0.024787\n",
              "11             0.346261  ...           0.027021\n",
              "12             0.319355  ...           0.029791\n",
              "13             0.295460  ...           0.031727\n",
              "14             0.274107  ...           0.033661\n",
              "15             0.254682  ...           0.035084\n",
              "16             0.237113  ...           0.035246\n",
              "17             0.221288  ...           0.037163\n",
              "18             0.206624  ...           0.037439\n",
              "19             0.193463  ...           0.038549\n",
              "20             0.181286  ...           0.040860\n",
              "21             0.170595  ...           0.041312\n",
              "22             0.160096  ...           0.042193\n",
              "23             0.150692  ...           0.042814\n",
              "24             0.142128  ...           0.044483\n",
              "25             0.134072  ...           0.046630\n",
              "26             0.127046  ...           0.047034\n",
              "27             0.120096  ...           0.049238\n",
              "28             0.113914  ...           0.050487\n",
              "29             0.108511  ...           0.052603\n",
              "30             0.103520  ...           0.053637\n",
              "31             0.098714  ...           0.055586\n",
              "32             0.094222  ...           0.057320\n",
              "33             0.090114  ...           0.057911\n",
              "34             0.086580  ...           0.060535\n",
              "35             0.083152  ...           0.061176\n",
              "36             0.079859  ...           0.062950\n",
              "37             0.076860  ...           0.064416\n",
              "38             0.074164  ...           0.067031\n",
              "39             0.071570  ...           0.066797\n",
              "40             0.069316  ...           0.067637\n",
              "\n",
              "[41 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfVrtLQ2BOnv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9225ed55-542c-4d02-c3a7-a2dfdce43eea"
      },
      "source": [
        "print(cvresult.shape)\n",
        "xgb1.set_params(n_estimators=cvresult.shape[0])\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(xgb1, X_train, y_train, cv=5)\n",
        "\n",
        "print(\"Accuracy of cross validation(train): %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "\n",
        "scores = cross_val_score(xgb1, X_test, y_test, cv=5)\n",
        "print(\"Accuracy of cross validation(test): %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(72, 4)\n",
            "Accuracy of cross validation(train): 0.9583 (+/- 0.09)\n",
            "Accuracy of cross validation(test): 0.9048 (+/- 0.16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awMOAKTBFwyi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "85c5cdcd-cb81-4e67-d848-9a62be9cf6cb"
      },
      "source": [
        "print(xgb1.feature_importances_)\n",
        "print(xgb1.get_booster().get_fscore())\n",
        "\n",
        "# importance_type = ['weight', 'gain', 'cover', 'total_gain', 'total_cover']\n",
        "print(xgb1.get_booster().get_score(importance_type='weight'))\n",
        "\n",
        "from xgboost import plot_importance\n",
        "plot_importance(xgb1)"
      ],
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.02989605 0.04874194 0.51202303 0.409339  ]\n",
            "{'f2': 174, 'f3': 110, 'f0': 53, 'f1': 60}\n",
            "{'f2': 174, 'f3': 110, 'f0': 53, 'f1': 60}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f40792fdc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 261
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs4AAAEWCAYAAAB2aRHzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luqAEOFxP8-Y",
        "colab_type": "text"
      },
      "source": [
        "### Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmYTz_ldWkTS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "05be2316-9a70-4c5a-e3b6-9e6534e24d1c"
      },
      "source": [
        "sorted(sklearn.metrics.SCORERS.keys())"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['accuracy',\n",
              " 'adjusted_mutual_info_score',\n",
              " 'adjusted_rand_score',\n",
              " 'average_precision',\n",
              " 'balanced_accuracy',\n",
              " 'brier_score_loss',\n",
              " 'completeness_score',\n",
              " 'explained_variance',\n",
              " 'f1',\n",
              " 'f1_macro',\n",
              " 'f1_micro',\n",
              " 'f1_samples',\n",
              " 'f1_weighted',\n",
              " 'fowlkes_mallows_score',\n",
              " 'homogeneity_score',\n",
              " 'jaccard',\n",
              " 'jaccard_macro',\n",
              " 'jaccard_micro',\n",
              " 'jaccard_samples',\n",
              " 'jaccard_weighted',\n",
              " 'max_error',\n",
              " 'mutual_info_score',\n",
              " 'neg_log_loss',\n",
              " 'neg_mean_absolute_error',\n",
              " 'neg_mean_squared_error',\n",
              " 'neg_mean_squared_log_error',\n",
              " 'neg_median_absolute_error',\n",
              " 'normalized_mutual_info_score',\n",
              " 'precision',\n",
              " 'precision_macro',\n",
              " 'precision_micro',\n",
              " 'precision_samples',\n",
              " 'precision_weighted',\n",
              " 'r2',\n",
              " 'recall',\n",
              " 'recall_macro',\n",
              " 'recall_micro',\n",
              " 'recall_samples',\n",
              " 'recall_weighted',\n",
              " 'roc_auc',\n",
              " 'v_measure_score']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPyJH484SlLG",
        "colab_type": "text"
      },
      "source": [
        "If a best param is on the boundary of the testing interval, we should try another interval to cover it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyZ0QGsJR9vT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "949e4c9c-6b37-4e56-c441-f6368c2152ce"
      },
      "source": [
        "param_test1 = {\n",
        "    'max_depth':range(3,10,2),\n",
        "    'min_child_weight':range(1,6,2)}\n",
        "\n",
        "gsearch1 = GridSearchCV(estimator = XGBClassifier(\n",
        "    learning_rate=0.1, n_estimators=41, max_depth=5,\n",
        "    min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
        "    objective= 'multi:softprob', nthread=4, scale_pos_weight=1, seed=27), \n",
        "    param_grid = param_test1, scoring='accuracy', n_jobs=4, iid=False, cv=5)\n",
        "\n",
        "gsearch1.fit(X_train, y_train)\n",
        "gsearch1.best_params_, gsearch1.best_score_"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'max_depth': 3, 'min_child_weight': 1}, 0.9499710144927537)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu9F8BLoTcHe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c1d64f52-a90c-412c-8e99-57bb1232481f"
      },
      "source": [
        "param_test2 = {\n",
        "    'max_depth':[1, 2, 3, 4],\n",
        "    'min_child_weight':[1, 2, 3]\n",
        "}\n",
        "gsearch2 = GridSearchCV(estimator = XGBClassifier(\n",
        "    learning_rate=0.1, n_estimators=41, max_depth=3,\n",
        "    min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
        "    objective= 'multi:softprob', nthread=4, scale_pos_weight=1, seed=27), \n",
        "    param_grid = param_test2, scoring='accuracy', n_jobs=4,iid=False, cv=5)\n",
        "\n",
        "gsearch2.fit(X_train, y_train)\n",
        "gsearch2.best_params_, gsearch2.best_score_"
      ],
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'max_depth': 1, 'min_child_weight': 1}, 0.9583043478260869)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7B_ukwu28kM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84f59262-c6f3-4dcc-ff57-f1dad62a7563"
      },
      "source": [
        "param_test3 = {\n",
        " 'gamma':[i/10.0 for i in range(0,5)]\n",
        "}\n",
        "gsearch2 = GridSearchCV(estimator = XGBClassifier(\n",
        "    learning_rate=0.1, n_estimators=41, max_depth=1,\n",
        "    min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
        "    objective= 'multi:softprob', nthread=4, scale_pos_weight=1, seed=27), \n",
        "    param_grid = param_test3, scoring='accuracy', n_jobs=4,iid=False, cv=5)\n",
        "\n",
        "gsearch2.fit(X_train, y_train)\n",
        "gsearch2.best_params_, gsearch2.best_score_"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'gamma': 0.0}, 0.9583043478260869)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_4BeVtyYRrv",
        "colab_type": "text"
      },
      "source": [
        "Before proceeding, a good idea would be to re-calibrate the number of boosting rounds for the updated parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9t3xN15Xnxj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b3d8009a-e2f0-4332-ceb8-0e7005cb628a"
      },
      "source": [
        "xgb2 = XGBClassifier(\n",
        "    learning_rate=0.1,\n",
        "    n_estimators=1000,\n",
        "    max_depth=1,\n",
        "    min_child_weight=1,\n",
        "    gamma=0,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    objective= 'multi:softprob',\n",
        "    num_class=3,\n",
        "    nthread=4,\n",
        "    scale_pos_weight=1,\n",
        "    seed=27)\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "xgb_param = xgb2.get_xgb_params()\n",
        "cvresult = xgb.cv(xgb_param, dtrain, \n",
        "                  num_boost_round = xgb1.get_params()['n_estimators'], \n",
        "                  nfold=5,\n",
        "                  metrics='mlogloss',\n",
        "                  early_stopping_rounds=50, \n",
        "                  stratified=True)\n",
        "\n",
        "print(\"best number of boosting rounds: \", cvresult.shape[0])\n",
        "xgb2.set_params(n_estimators=cvresult.shape[0])\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(xgb2, X_train, y_train, cv=5)\n",
        "print(\"Accuracy of cross validation(train): %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "scores = cross_val_score(xgb2, X_test, y_test, cv=5)\n",
        "print(\"Accuracy of cross validation(test): %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best number of boosting rounds:  72\n",
            "Accuracy of cross validation(train): 0.9583 (+/- 0.09)\n",
            "Accuracy of cross validation(test): 0.9048 (+/- 0.16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a9XSkgUY35F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebe32709-260c-48e8-f006-31da1d28d75d"
      },
      "source": [
        "param_test4 = {\n",
        "    'subsample':[i/10.0 for i in range(6,10)],\n",
        "    'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
        "}\n",
        "gsearch4 = GridSearchCV(estimator = XGBClassifier(\n",
        "    learning_rate=0.1, n_estimators=72, max_depth=1,\n",
        "    min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
        "    objective= 'multi:softprob', nthread=4, scale_pos_weight=1, seed=27), \n",
        "    param_grid = param_test4, scoring='accuracy', n_jobs=4,iid=False, cv=5)\n",
        "\n",
        "gsearch4.fit(X_train, y_train)\n",
        "gsearch4.best_params_, gsearch2.best_score_"
      ],
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'colsample_bytree': 0.6, 'subsample': 0.6}, 0.9583043478260869)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekSly8cNapm0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5f7ddc5-44db-444a-9367-14b2a7b27386"
      },
      "source": [
        "param_test5 = {\n",
        "    'subsample':[i/100.0 for i in range(55,65,5)],\n",
        "    'colsample_bytree':[i/100.0 for i in range(55,65,5)]\n",
        "}\n",
        "gsearch5 = GridSearchCV(estimator = XGBClassifier(\n",
        "    learning_rate=0.1, n_estimators=72, max_depth=1,\n",
        "    min_child_weight=1, gamma=0, subsample=0.6, colsample_bytree=0.6,\n",
        "    objective= 'multi:softprob', nthread=4, scale_pos_weight=1, seed=27), \n",
        "    param_grid = param_test5, scoring='accuracy', n_jobs=4,iid=False, cv=5)\n",
        "\n",
        "gsearch5.fit(X_train, y_train)\n",
        "gsearch5.best_params_, gsearch5.best_score_"
      ],
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'colsample_bytree': 0.55, 'subsample': 0.6}, 0.9583043478260869)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 281
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnUad05UcmbN",
        "colab_type": "text"
      },
      "source": [
        "Tuning Regularization Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y91yeNLc3oS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2779b5d8-f424-4282-bd42-97a003ac79d8"
      },
      "source": [
        "param_test6 = {\n",
        "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100],\n",
        "    'reg_lambda':[1e-5, 1e-2, 0.1, 1, 100]\n",
        "}\n",
        "\n",
        "gsearch6 = GridSearchCV(estimator = XGBClassifier(\n",
        "    learning_rate=0.1, n_estimators=72, max_depth=1,\n",
        "    min_child_weight=1, gamma=0, subsample=0.6, colsample_bytree=0.55,\n",
        "    objective= 'multi:softprob', nthread=4, scale_pos_weight=1, seed=27), \n",
        "    param_grid = param_test6, scoring='accuracy', n_jobs=4,iid=False, cv=5)\n",
        "\n",
        "gsearch6.fit(X_train, y_train)\n",
        "gsearch6.best_params_, gsearch6.best_score_"
      ],
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'reg_alpha': 1e-05, 'reg_lambda': 1e-05}, 0.9663043478260869)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 296
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLoWQqepdF_b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d40114d-f89c-4b72-bae4-29a341fcd1f3"
      },
      "source": [
        "param_test7 = {\n",
        "    'reg_alpha':[0, 1e-6, 5*1e-6, 1e-5, 5*1e-5],\n",
        "    'reg_lambda':[0, 1e-6, 5*1e-6, 1e-5, 5*1e-5]\n",
        "}\n",
        "\n",
        "gsearch7 = GridSearchCV(estimator = XGBClassifier(\n",
        "    learning_rate=0.1, n_estimators=72, max_depth=1,\n",
        "    min_child_weight=1, gamma=0, subsample=0.6, colsample_bytree=0.55,\n",
        "    objective= 'multi:softprob', nthread=4, scale_pos_weight=1, seed=27), \n",
        "    param_grid = param_test7, scoring='accuracy', n_jobs=4,iid=False, cv=5)\n",
        "\n",
        "gsearch7.fit(X_train, y_train)\n",
        "gsearch7.best_params_, gsearch7.best_score_"
      ],
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'reg_alpha': 0, 'reg_lambda': 0}, 0.9663043478260869)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHzXtd-BdX5k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "00d76ac2-4d5a-4df6-e934-93ccc92522f0"
      },
      "source": [
        "xgb3 = XGBClassifier(\n",
        "    learning_rate=0.1,\n",
        "    n_estimators=1000,\n",
        "    max_depth=1,\n",
        "    min_child_weight=1,\n",
        "    gamma=0,\n",
        "    subsample=0.6,\n",
        "    colsample_bytree=0.55,\n",
        "    reg_alpha=0,\n",
        "    reg_lambda=0,\n",
        "    objective= 'multi:softprob',\n",
        "    num_class=3,\n",
        "    nthread=4,\n",
        "    scale_pos_weight=1,\n",
        "    seed=27)\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "xgb_param = xgb3.get_xgb_params()\n",
        "cvresult = xgb.cv(xgb_param, dtrain, \n",
        "                  num_boost_round = xgb1.get_params()['n_estimators'], \n",
        "                  nfold=5,\n",
        "                  metrics='mlogloss',\n",
        "                  early_stopping_rounds=50, \n",
        "                  stratified=True)\n",
        "\n",
        "print(\"best number of boosting rounds: \", cvresult.shape[0])\n",
        "xgb3.set_params(n_estimators=cvresult.shape[0])\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(xgb3, X_train, y_train, cv=5)\n",
        "print(\"Accuracy of cross validation(train): %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "scores = cross_val_score(xgb3, X_test, y_test, cv=5)\n",
        "print(\"Accuracy of cross validation(test): %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 319,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best number of boosting rounds:  72\n",
            "Accuracy of cross validation(train): 0.9663 (+/- 0.10)\n",
            "Accuracy of cross validation(test): 0.9667 (+/- 0.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "518tSMCkg-Va",
        "colab_type": "text"
      },
      "source": [
        "Reducing Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh1MIEp_g-8W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2689a7eb-df40-4b71-d5ec-54a0b1352391"
      },
      "source": [
        "final_params = {\n",
        "    'learning_rate': 0.08,\n",
        "    'n_estimators': 1000,\n",
        "    'max_depth': 1,\n",
        "    'min_child_weight': 1,\n",
        "    'gamma': 0,\n",
        "    'subsample': 0.6,\n",
        "    'colsample_bytree': 0.55,\n",
        "    'reg_alpha': 0,\n",
        "    'reg_lambda': 0,\n",
        "    'objective': 'multi:softprob',\n",
        "    'num_class': 3,\n",
        "    'nthread': 4,\n",
        "    'scale_pos_weight': 1,\n",
        "    'seed': 27 }\n",
        "\n",
        "xgb4 = XGBClassifier(**final_params)\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "xgb_param = xgb4.get_xgb_params()\n",
        "cvresult = xgb.cv(xgb_param, dtrain, \n",
        "                  num_boost_round = xgb1.get_params()['n_estimators'], \n",
        "                  nfold=5,\n",
        "                  metrics='mlogloss',\n",
        "                  early_stopping_rounds=50, \n",
        "                  stratified=True)\n",
        "\n",
        "print(\"best number of boosting rounds: \", cvresult.shape[0])\n",
        "xgb4.set_params(n_estimators=cvresult.shape[0])\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(xgb4, X_train, y_train, cv=5)\n",
        "print(\"Accuracy of cross validation(train): %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "scores = cross_val_score(xgb4, X_test, y_test, cv=5)\n",
        "print(\"Accuracy of cross validation(test): %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best number of boosting rounds:  72\n",
            "Accuracy of cross validation(train): 0.9663 (+/- 0.10)\n",
            "Accuracy of cross validation(test): 0.9667 (+/- 0.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8HfNBmjmXXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}