{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gernerative.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPUWBe7/ifxDArQzCP6SNqc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minghsu0107/ML/blob/master/my-keras/generative.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXD-hayrXbnX",
        "colab_type": "text"
      },
      "source": [
        "# 使用 LSTM 產生文字資料"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CBDCQlDXdee",
        "colab_type": "text"
      },
      "source": [
        "### 建立針對不同的 temperature 設定，重新加權，計算新的機率分佈的函式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fTwgZckXcS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def reweight_distribution(original_distribution, temperature=2):\n",
        "    distribution = np.log(original_distribution) / temperature\n",
        "    distribution = np.exp(distribution)\n",
        "    return distribution / np.sum(distribution)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEG28OzpX01D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fa3334ef-3382-4b1d-da93-47b41134ebc0"
      },
      "source": [
        "ori_dstri = np.array([0.8, 0.1, 0.1])   # a、b、c 的機率分布\n",
        "\n",
        "new_dstri = reweight_distribution(ori_dstri, \n",
        "                                  temperature=0.01)  # 使用溫度 0.01 \n",
        "print(new_dstri)    # [1.00000000e+00 4.90909347e-91 4.90909347e-91]\n",
        "\n",
        "new_dstri = reweight_distribution(ori_dstri, \n",
        "                                  temperature=2) # 使用預設溫度 2\n",
        "print(new_dstri)    # [0.58578644 0.20710678 0.20710678]\n",
        "\n",
        "new_dstri = reweight_distribution(ori_dstri, \n",
        "                                  temperature=10) # 使用溫度 10\n",
        "print(new_dstri)    # [0.38102426 0.30948787 0.30948787], nearly well-distributed"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.00000000e+00 4.90909347e-91 4.90909347e-91]\n",
            "[0.58578644 0.20710678 0.20710678]\n",
            "[0.38102426 0.30948787 0.30948787]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKk-B8jTYd5A",
        "colab_type": "text"
      },
      "source": [
        "### 字元級 LSTM 文字生成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaL7SBh8X51Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cefa926b-88ac-47f9-ec77-bf6b87dde6bb"
      },
      "source": [
        " import keras\n",
        "import numpy as np\n",
        "\n",
        "path = keras.utils.get_file(        # 取得文本檔案\n",
        "    'nietzsche.txt',                # 檔名 \n",
        "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')  # 檔案位置\n",
        "text = open(path, encoding='utf-8').read().lower()    # 讀取文本內容，並轉成小寫\n",
        "print('Corpus length:', len(text))  # 文本長度為 600893"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus length: 600893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9wsRBrDYVYs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a682a2ee-fc75-4903-ae3b-e5a58eb530a3"
      },
      "source": [
        "maxlen = 60     # 每次 (step) 從文本中萃取 60 個字元作為序列資料\n",
        "step = 3        # 每 3 個字元為一個 step 進行萃取 \n",
        "\n",
        "sentences = []  # 存放萃取出的序列資料\n",
        "next_chars = [] # 存放對應目標 (萃取出來的序列資料的後一個字元)\n",
        "\n",
        "# 萃取序列資料 \n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('Number of sequences:', len(sentences))   # 共萃取出 200278 個序列資料\n",
        "\n",
        "# 產生文本中的 \"唯一\" 字元串列 (文本轉成 set 將重複字元刪除)\n",
        "chars = sorted(list(set(text))) \n",
        "print('Unique characters:', len(chars)) # 文本共使用 57 種字元\n",
        "\n",
        "# 將各個字元對應到 \"chars\" 串列中的索引值成為字典 (dict) 格式。即 {'\\n': 0,' ': 1, '!': 2,…}\n",
        "char_indices = dict((char, chars.index(char)) for char in chars)\n",
        "\n",
        "# 將字元經 One-hot 編碼成二元陣列\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "print(x.shape)  # (200278, 60, 57)\n",
        "print(y.shape)  # (200278, 57)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sequences: 200278\n",
            "Unique characters: 57\n",
            "Vectorization...\n",
            "(200278, 60, 57)\n",
            "(200278, 57)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebGSZY2lZyuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import layers\n",
        "\n",
        "model = keras.models.Sequential()   # 建立序列式模型\n",
        "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(layers.Dense(len(chars), activation='softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IObbvF_ST25o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature     # 重新加權計算 (熵)\n",
        "    exp_preds = np.exp(preds)               \n",
        "    preds = exp_preds / np.sum(exp_preds)   \n",
        "    probas = np.random.multinomial(1, preds, size=1) # 丟入多項式分布中共取樣1次; (size=1: 實驗進行1次)\n",
        "    # example: preds=[1, 2, 3] -> probas=[[0, 0, 1]] (在一次實驗中：1出現0次, 2出現0次, 3出現1次; 共取樣1次)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ScuEnnuUzlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import sys\n",
        "\n",
        "for epoch in range(1, 61):  # 共 60 個訓練週期 (次數)\n",
        "    print('epoch', epoch)\n",
        "    model.fit(x, y,         # 用萃取出來的 x, y 開始進行訓練\n",
        "              batch_size=128,\n",
        "              epochs=1)\n",
        "    # 隨機選擇文本中的某段 60 個字元\n",
        "    start_index = random.randint(0, len(text) - maxlen)\n",
        "    generated_text = text[start_index: start_index + maxlen]\n",
        "    print('--- 隨機初始文字: \"' + generated_text + '\"')\n",
        "\n",
        "    # 嘗試使用一系列不同 temperature 生成文字\n",
        "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('------ temperature:', temperature)\n",
        "        sys.stdout.write(generated_text)\n",
        "\n",
        "        # 每個 temperature 生成 400 個字元\n",
        "        for i in range(400):    \n",
        "            sampled = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(generated_text):\n",
        "                sampled[0, t, char_indices[char]] = 1.\n",
        "            preds = model.predict(sampled, verbose=0)[0]    # 產生字元機率分布\n",
        "            next_index = sample(preds, temperature) # 重新加權並取樣，回傳字元索引\n",
        "            next_char = chars[next_index]           # 確認新字元\n",
        "            generated_text += next_char             # 新字元加到文字的後方\n",
        "            generated_text = generated_text[1:]     # 重新取得含括新字元的文字繼續生成下一個字元\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}